{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of characters: 21883\n"
     ]
    }
   ],
   "source": [
    "with open(\"/home/farzin/AI/Sebastian Raschka/data/The_Verdict.txt\", \"r\") as f:\n",
    "    raw_text = f.read()\n",
    "\n",
    "\n",
    "print(\"Total number of characters:\", len(raw_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Verdict\\nEdith Wharton\\n\\n1908\\n\\nExported from Wikisource on December 20, 2024\\n\\n1\\n\\n\\x0cI HAD always th'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_text[:99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of words: 8849\n"
     ]
    }
   ],
   "source": [
    "# Using regular expression will split the text into words\n",
    "import re\n",
    "\n",
    "preprocessed_text = re.split(r'([,.:;?_!\"()\\']|--|\\s)', raw_text)\n",
    "print(\"Total number of words:\", len([word for word in preprocessed_text if word]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', ' ', 'Verdict', '\\n', 'Edith', ' ', 'Wharton', '\\n', '', '\\n', '1908', '\\n', '', '\\n', 'Exported', ' ', 'from', ' ', 'Wikisource', ' ', 'on', ' ', 'December', ' ', '20', ',', '', ' ', '2024', '\\n', '', '\\n', '1', '\\n', '', '\\n', '', '\\x0c', 'I', ' ', 'HAD', ' ', 'always', ' ', 'thought', ' ', 'Jack', ' ', 'Gisburn', ' ', 'rather', ' ', 'a', ' ', 'cheap', ' ', 'genius-though', ' ', 'a', ' ', 'good', ' ', 'fellow', ' ', 'enough', '--', 'so', ' ', 'it', ' ', 'was', ' ', 'no', ' ', 'great', ' ', 'surprise', ' ', 'to', '\\n', 'me', ' ', 'to', ' ', 'hear', ' ', 'that', ',', '', ' ', 'in', ' ', 'the', ' ', 'height', ' ', 'of', ' ', 'his']\n"
     ]
    }
   ],
   "source": [
    "print(preprocessed_text[:99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique tokens: 1259\n"
     ]
    }
   ],
   "source": [
    "# Unique tokens\n",
    "print(\"Number of unique tokens:\", len(set(preprocessed_text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'', 'simply', 'breathing', 'felt', 'through', 'Mr', 'same', 'pleased', 'Those', 'flowers', 'novels', 'than', 'away', 'cleverer', '20', 'mine', 'grew', 'easel', 'domain', 'lift', 'azaleas', 'year', 'Thwing', 'followed', 'cry', 'errors', 'Usually', 'sure', 'answered', 'expected', 'great', 'brown', 'didn', 'fashionable', 'though', 'published', 'light', 'twirling', 'mere', 'Gideon', 'fate', 'delicate', 'Has', 'knees', '!', 'inflexible', 'But', 'welcome', 'uncertain', 'being', 'even', 'excusing', 'foreign', 'want', 'long', 'echoed', 'honour', 'very', 'fewer', 'resolve', 'happened', 'gesture', 'rule', 'all', 'neutral', 'voice', 'artist', 'Gallery', 'deprecatingly', 'won', 'craft', 'give', 'users', 'widow', 'cigarette', '15', 'donkey', 'appearance', 'leathery', 'panelling', 'Miss', 'reason', 'add', 'much', 'always', 'accustomed', 'nervousness', 'stay', 'value', 'other', 'history', 'committed', 'When', 'compared', 'point', 'good-humoured', 'truth', 'we', 'it', 'Come', 'at', 'exquisite', 'Perhaps', 'drawing-rooms', 'Russian', '11', 'big', 'ones', 'satisfaction', 'onto', 'straining', 'At', 'looking', 'seen', 'apparent', 'excuse', 'footstep', 'reproduction', 'standing', 'idea', 'on', 'don', 'your', 'why', 'murmur', 'upset', 'modest', '9', 'suffered', 'married', 'was', 'height', 'arm-chair', 'looked', 'remember', 'tired', 'forgotten', 'suggested', 'too', 'drew', 'Dschwen', 'run', 'charming', 'passing', 'posing', 'pardonable', 'discovery', 'boudoir', 'line', 'cigar', 'commercial', 'pictures', 'slight', 'met', 'modesty', 'quote', 'savour', 'recovering', 'Boris23', 'apparently', 'exquisitely', 'bear', 'Bender235', 'predicted', 'mysterious', 'irony', 'Suddenly', 'tinge', '--', 'there', 'marble', 'continued', 't', 'easy', 'home', 'full', 'women', 'garlands', 'called', 'constantly', 'fair', 'alive', 'rs', 'fragments', 'hall', 'frames', 'next', 'presenting', 'academic', 'day', 'activity', 'PatríciaR', 'Reisio', 'finality', 'starting', 'license', 'heard', '21', 'amusing', 'sitters', 'dining-room', 'brought', 'bean-stalk', 'comes', 'incense', 'technicalities', 'first', 'deprecating', 'Mrs', 'Edith', 'sugar', 'luxury', 'morbidly', 'seemed', 'glanced', 'some', 'confident', 'Or', 'adopted', 'Are', 'hanging', 'passages', 'added', 'bric-a-brac', 'Hermia', 'lent', 'are', 'sunlit', 'wander', 'after', 'left', 'endless', 'romantic', 'like', 'effects', 'nervous', 'lingered', 'beard', 'appeared', 'every', 'upstairs', 'Exported', 'whenever', 'their', '5', 'Rocket000', 'things', 'Never', 'Rome', 'kept', 'tones', 'man', 'dabble', 'brings', 'did', 'wits', 'hand', 're', 'wonder', 'fit', 'wife', 'down', 'latter', 'Moon-dancers', 'coat', 'cigars', 'ridiculous', 'How', 'Grindle', 'loathing', 'you', 'or', 'protest', 'wondered', 'familiar', 'curious', 'speculations', 'yet', 'Of', 'stand', 'articles', 'off', 'while', 'pale', 'destruction', 'lips', 'proclaiming', 'lies', 'began', 'fingers', 'Nutley', 'desire', 'timorously', 'grace', 'wants', 'On', 'surface', 'made', 'do', 'developing', 'stocked', 'equanimity', 'friend', 'each', 'adulation', 'failed', 'look', 'Devonshire', 'glad', 'house', 'villa', 'again', 'quickly', 'smiling', 'us', 'suburban', 'longed', 'haven', 'e-books', 'quietly', 'hardly', 'diagnosis', 'preliminary', 'Dbenbenn', 'the', 'were', 'work', 'but', 'forgive', 'economy', 'he', 'toward', 'couldn', 'atom', 'believed', 'Only', 'money', 'see', 'ever', 'proofreading', 'disdained', 'Money', 'if', 'audacities', 'say', 'fluently', 'really', '-she', ':', 'yellow', '8', 'Among', 'wide', 'appointed', 'underneath', 'borne', 'him', 'painter-ah', 'which', 'part', 'how', '17', 'dissatisfied', 'white', 'January', 'remained', 'ironic', 'course', 'chucked', 'led', 'dozen', 'extracting', 'drawn', 'ourselves', 'when', 'States', 'event', 'blocked', '6', 'untouched', '12', 'central', 'members', 'surprised', 'atmosphere', 'bronzes', 'term', 'flung', 'Though', 'went', 'under', 'three', 'terrace', 'sunburnt', 'upon', 'As', 'becoming', 'says', 'whom', 'trace', 'During', 'trade', 'faded', 'stopped', 'lightly', 'His', 'deep', 'because', 'cured', 'minutes', 'poverty', 'possessed', 'curiosity', 'flash', 'circulation', 'Burlington', 'strain', 'conjugal', 'problem', 'velveteen', 'am', 'corrected', 'quality', 'lean', 'sweetly', 'thought', 'pride', 'they', 'must', 'answer', 'hard', 'where', 'sign', 'lines', 'a', 'irrevocable', 'use', 'able', 'Jack', 'traps', 'room', 'Don', 'unaccountable', 'question', '(', 'e-book', 'beneath', 'is', 'curtains', 'placed', 'arms', 'chair', 'younger', 'be', 'dropped', 'got', 'pushed', 'of', 'Pathosbot', 'platitudes', 'll', 'pastels', 'idle', 'have', 'afraid', 'dingy', 'distract', 'career', 'corner', 'slowly', 'any', 'oval', 'escape', 'repeating', 'enjoy', 'now', 'small', 'bitterness', 'choice', 'basking', 'stuff', 'should', 'therefore', 'resented', 'persistence', 'collection', 'Dubarry', 'gave', 'half-light', 'once', 'copyrighted', 'business', 'started', 'countries', 'to', '\\x0c', 'briefly', 'About', 'me', 'only', 'swum', 'hours', 'by', '\\n', 'bull', 'furrowed', 'dear', 'prodigious', 'solace', 'Why', 'library', 'pathos', 'free', 'axioms', 'him-or', 'immediately', 'no', '16', 'purely', 'amplest', 'glimpse', 'spaniel', 'leisure', 'wouldn', 'crossed', 'past', 'stood', 'muddling', 'showy', 'single', 'perfect', 'end', 'paled', 'enlightenment', 'glory', 'dead', 'feather', 'sitter-deploring', 'reflection', 'tottering', 'along', 'asked', 'Zigzig20s~enwikisource', 'sensitive', 'wanted', 'exterminating', 'Venetian', 'none', 'pockets', 'characteristic', 'shrugged', 'divert', 'perceptible', 'laid', 'terribly', 'Chicago', 'disease', 'pretty', 'painted', 'disdain', 'vocation', 'veins', 'failure', 'd', 'place', 'longer', 'Grafton', 'into', 's', 'breaking', 'forehead', 'silver', '\"', 'digital', 'late', 'gradually', 'And', 'elegant', 'Yes', 'minute', 'forming', 'Emperors', 'watched', 'leave', 'mourn', 'hide', 'including', 'sunburn', 'over', 'attitude', 'clue', 'Had', 'Commons', 'scornful', 'Riviera', 'simpleton', 'faces', 'this', 'fullest', 'FDL', 'contended', 'pines', '2', 'covered', 'used', 'tribute', 'happen', '4', 'magazines', 'unusual', 'himself', 'never', 'discrimination', 'anything', 'yourself', 'robbed', 'oh', 'sweetness', 'going', 'prism', 'lends', 'technique', 'send', 'couple', 'loss', 'moustache', 'distribute', 'tempting', 'wish', 'Tene~commonswiki', 'spacious', 'publications', 'purpose', 'patient', 'detail', 'dragged', 'Creative', 'out', 'Just', 'window-curtains', 'equally', 'my', 'exploitation', 'report', 'They', 'them', 'vases', '22', 'white-panelled', 'Renaissance', 'good-breeding', 'trouser-presses', 'laughed', 'struck', 'monumental', 'growing', 'Croft', 'chap', 'poised', 'hung', 'instinctively', '0', 'profusion', 'least', 'absurdity', 'what', 'millionaire', 'What', 'ensuing', 'United', 'people', 'frame', 'told', 'hear', 'muscles', 'multilingual', 'terraces', 'letters', 'balance', 'gray', 'may', 'following', 'self-confident', 'bravura', 'price', '.', 'hadn', 'thin', 'shirked', 'copyright', 'its', 'circumstance', 'up', 'balustraded', 'aesthetic', 'since', 'native', 'Attribution-ShareAlike', 'rest', 'bed', 'abdication', 'If', 'comfortable', 'cried', 'inevitably', 'December', 'current', 'cheeks', 'fancy', 'fell', 'areas', 'vista', 'shall', 'new', 'represented', 'mentioned', 'frequently', 'similar', 'eighteenth-century', 'crowned', 'Once', 'pink', 'eyes', 'KABALINI', 'scorn', 'alone', 'hair', 'Stroud', 'idling', 'HAD', 'last', 'live', 'irrelevance', 'life-likeness', 'lair', 'straight', 'We', 'turned', 'watching', 'existed', 'bits', 'that', 'woman', 'would', 'contributed', 'little', 'worth', 'My', 'Professional', 'behind', 'Jacobolus', 'egregious', ' ', 'flashed', 'florid', 'Unported', 'oak', 'somebody', 'complex', 'extenuation', 'sight', 'air', 'cards', 'lucky', 'eyebrows', 'apply', 'transcription', 'random', 'destroyed', 'get', 'half', 'handsome', 'language', 'works', 'online', 'Ah', 'transmute', 'dim', 'faith', 'few', 'garlanded', 'came', 'everlasting', 'greatest', 'took', 'dashed', 'strokes', 'Technion', '14', 'groping', 'Zscout370', 'spite', 'sneer', 'studio', 'sent', 'paint', 'unexpected', 'feet', 'those', 'then', 'strongly', 'above', 'shoulders', 'damask', 'dimmest', 'saying', 'been', 'rich', 'break', 'queerly', '7', 'holding', 'true', 'meant', 'reared', 'degree', 'indifferent', 'Indolences', 'tell', 'arm', 'regrets', 'strongest', 'shade', 'face', 'found', 'To', 'strolled', 'vindicated', 'Oh', 'Made', 'clear', 'fitting', 'speaking-tubes', 'eye', 'Destroyed', 'Well', 'follow', 'slightly', 'moved', 'across', 'not', 'shaking', 'find', 'wasn', 'twice', 'lit', 'thither', 'Her', 'can', 'stairs', 'dark', 'travelled', 'done', 'gloried', 'negatived', 'lifted', 'distinguished', 'luncheon-table', 'Be', 'fact', 'getting', 'such', 'short', 'coming', 'doing', 'Now', 'gone', 'from', 'ago', 'has', 'smile', 'among', '1908', 'rain', 'princely', 'most', 'foundations', 'A', 'close', 'forced', 'twenty-four', 'purblind', 'herself', 'dress-closets', 'here', 'books', 'with', 'swept', 'quite', 'surprise', 'There', 'superb', 'weekly', 'days', 'let', 'background', '18', 'bath-rooms', 'in', 'afterward', 'half-mechanically-', 'Jarekt', 'hermit', 'word', 'shoulder', 'caught', 'time', 'object', 'In', 'beaming', 'discussion', 'Bromskloss', 'ease', 'substantial', 'oddly', 'hesitations', 'domestic', 'up-stream', 'crumbled', 'You', 'attention', 'waves', 'one', 'lovely', 'come', 'good', 'another', 'rather', 'for', 'deerhound', '19', 'formed', 'book', 'qualities', 'Greek', 'weeks', 'Was', 'table', '?', 'as', 'tells', 'resources', 'genial', 'given', 'check', 'hands', 'buying', 'managed', 'laugh', 'obituary', 'knew', 'something', 'splash', 'Carlo', 'secret', 'tributes', 'enabled', 'landing', 'could', 'He', 'amid', 'prestidigitation', 'etching', 'still', 'poor', 'about', 'multiplied', 'hot-house', 'Gisburns', 'stopping', 'It', 'think', 'mediocrity', 'twenty', 'admirers', 'talking', 'know', 'terms', 'between', 'denied', 'husband', 'canvas', 'painter', 'wincing', 'threshold', 'his', 'Thwings', 'straddling', 'mantel-piece', 'strange', 'put', 'absolute', 'demand', ';', 'I', 'back', 'poems', 'sketch', 'built', 'begun', 'nymphs', 'underlay', 'stammer', 'interesting', 'might', 'Strouds', 'itself', 'whole', 'Gisburn', 'showed', 'often', 'threw', 'Begin', 'Wharton', '10', 'raised', 'shorter', 'swelling', 'moment', 'paid', 'greatness', 'head', 'better', 'insignificant', 'edition', 'insensible', 'GNU', 'till', 'she', 'our', 'who', 'near', 'forcing', 'heart', 'furiously', 'display', 'straw', 'accessible', 'lump', 'consummate', 'Hang', 'except', 'Verdict', 'wall', 'more', 'tea', 'possible', 'later', 'suddenly', 'beauty', 'surest', 'kind', 'colour', 'died', 'Claude', 'so', 'portrait', 'instructive', 'Lord', 'Then', '1929', 'Wikisource', 'fond', ',', 'AdamBMorgan', 'aside', 'public', 'her', 'recreated', 'companion', 'water-colour', 'chest', 'square', 'brush', 'jealousy', 'five', 'genius-though', 'lounging', 'plain', 'Jove', 'prove', 'care', 'taken', 'forward', 'form', 'earth', 'open', 'Zhaladshar', 'Florence', 'note', 'palm-trees', 'Abigor', 'rose', 'throwing', 'usual', '1', 'mourned', 'sex', 'page', 'working', 'jardiniere', 'By', 'previous', 'tone', 'silent', 'famille-verte', 'mood-rather', 'arm-chairs', 'make', 'had', 'drawing-room', 'chimney-piece', 'stream', 'Blurpeace', 'fellow', 'touched', 'count', 'subject', 'fostered', 'disguised', 'AzaToth', 'She', 'having', 'pardoned', 'set', 'That', 'picture', 'outline', 'This', 'just', 'Dha', 'hint', 'merely', 'nearly', 'inevitable', 'embarrassed', 'bespoke', 'terra-cotta', 'absorbed', 'lose', 'persuasively', 'false', 'awful', 'packed', 'grayish', 'tricks', 'reminded', 'Victor', 'sensation', 'hooded', 'saw', 'panel', 'lying', 'naive', 'became', 'Poor', 'mighty', 'thing', 'Arrt', 'circus-clown', 'skill', 'advance', '2024', 'wild', 'tears', 'volunteers', 'phrase', 'tie', 'clasping', 'way', 'deadening', 'real', 'constraint', 'learned', 'varnishing', 'cheap', 'art', 've', 'Steinsplitter', 'simplifications', 'amazement', 'serious', 'high', '13', 'collapsed', 'before', 'enough', 'almost', 'an', 'relatively', 'herself-', 'stroke', 'without', 'No', 'and', 'years', 'hostess', 'hour', 'abruptly', 'Rickham', \"'\", 'old', 'own', 'mirrors', 'Monte', 'congesting', 'go', 'countenance', 'desultory', 'nothing', 'exasperated', 'medium', 'For', 'canvases', 'reflected', 'painting', 'foreseen', 'reassurance', 'tried', 'Sevres', 'else', 'doesn', 'understand', '_', 'effect', 'lay', 'anywhere', 'The', 'suspected', 'established', 'fragment', 'known', 'accuse', 'efforts', 'manage', 'surrounded', 'elbow', 'objects', 'affect', 'virtuosity', 'claimed', 'Grindles', ')', 'disarming', 'occurred', 'born', 'attack', 'said', 'myself', 'balancing', 'show', 'leading', 'tips', 'take', '3', 'shrug', 'life', 'liked', 'keep'}\n"
     ]
    }
   ],
   "source": [
    "# all the unique tokens\n",
    "print(set(preprocessed_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'Verdict',\n",
       " 'Edith',\n",
       " 'Wharton',\n",
       " '1908',\n",
       " 'Exported',\n",
       " 'from',\n",
       " 'Wikisource',\n",
       " 'on',\n",
       " 'December',\n",
       " '20',\n",
       " ',',\n",
       " '2024',\n",
       " '1',\n",
       " 'I',\n",
       " 'HAD',\n",
       " 'always',\n",
       " 'thought',\n",
       " 'Jack',\n",
       " 'Gisburn',\n",
       " 'rather',\n",
       " 'a',\n",
       " 'cheap',\n",
       " 'genius-though',\n",
       " 'a',\n",
       " 'good',\n",
       " 'fellow',\n",
       " 'enough',\n",
       " '--',\n",
       " 'so',\n",
       " 'it',\n",
       " 'was',\n",
       " 'no',\n",
       " 'great',\n",
       " 'surprise',\n",
       " 'to',\n",
       " 'me',\n",
       " 'to',\n",
       " 'hear',\n",
       " 'that',\n",
       " ',',\n",
       " 'in',\n",
       " 'the',\n",
       " 'height',\n",
       " 'of',\n",
       " 'his',\n",
       " 'glory',\n",
       " ',',\n",
       " 'he',\n",
       " 'had',\n",
       " 'dropped',\n",
       " 'his',\n",
       " 'painting',\n",
       " ',',\n",
       " 'married',\n",
       " 'a',\n",
       " 'rich',\n",
       " 'widow',\n",
       " ',',\n",
       " 'and',\n",
       " 'established',\n",
       " 'himself',\n",
       " 'in',\n",
       " 'a',\n",
       " 'villa',\n",
       " 'on',\n",
       " 'the',\n",
       " 'Riviera',\n",
       " '.',\n",
       " '(',\n",
       " 'Though',\n",
       " 'I',\n",
       " 'rather',\n",
       " 'thought',\n",
       " 'it',\n",
       " 'would',\n",
       " 'have',\n",
       " 'been',\n",
       " 'Rome',\n",
       " 'or',\n",
       " 'Florence',\n",
       " '.',\n",
       " ')',\n",
       " '\"',\n",
       " 'The',\n",
       " 'height',\n",
       " 'of',\n",
       " 'his',\n",
       " 'glory',\n",
       " '\"',\n",
       " '--',\n",
       " 'that',\n",
       " 'was',\n",
       " 'what',\n",
       " 'the',\n",
       " 'women',\n",
       " 'called',\n",
       " 'it',\n",
       " '.',\n",
       " 'I',\n",
       " 'can',\n",
       " 'hear',\n",
       " 'Mrs',\n",
       " '.',\n",
       " 'Gideon',\n",
       " 'Thwing',\n",
       " '--',\n",
       " 'his',\n",
       " 'last',\n",
       " 'Chicago',\n",
       " 'sitter-deploring',\n",
       " 'his',\n",
       " 'unaccountable',\n",
       " 'abdication',\n",
       " '.',\n",
       " '\"',\n",
       " 'Of',\n",
       " 'course',\n",
       " 'it',\n",
       " \"'\",\n",
       " 's',\n",
       " 'going',\n",
       " 'to',\n",
       " 'send',\n",
       " 'the',\n",
       " 'value',\n",
       " 'of',\n",
       " 'my',\n",
       " 'picture',\n",
       " \"'\",\n",
       " 'way',\n",
       " 'up',\n",
       " ';',\n",
       " 'but',\n",
       " 'I',\n",
       " 'don',\n",
       " \"'\",\n",
       " 't',\n",
       " 'think',\n",
       " 'of',\n",
       " 'that',\n",
       " ',',\n",
       " 'Mr',\n",
       " '.',\n",
       " 'Rickham',\n",
       " '--',\n",
       " 'the',\n",
       " 'loss',\n",
       " 'to',\n",
       " 'Arrt',\n",
       " 'is',\n",
       " 'all',\n",
       " 'I',\n",
       " 'think',\n",
       " 'of',\n",
       " '.',\n",
       " '\"',\n",
       " 'The',\n",
       " 'word',\n",
       " ',',\n",
       " 'on',\n",
       " 'Mrs',\n",
       " '.',\n",
       " 'Thwing',\n",
       " \"'\",\n",
       " 's',\n",
       " 'lips',\n",
       " ',',\n",
       " 'multiplied',\n",
       " 'its',\n",
       " '_',\n",
       " 'rs',\n",
       " '_',\n",
       " 'as',\n",
       " 'though',\n",
       " 'they',\n",
       " 'were',\n",
       " 'reflected',\n",
       " 'in',\n",
       " 'an',\n",
       " 'endless',\n",
       " 'vista',\n",
       " 'of',\n",
       " 'mirrors',\n",
       " '.',\n",
       " 'And',\n",
       " 'it',\n",
       " 'was',\n",
       " 'not',\n",
       " 'only',\n",
       " 'the',\n",
       " 'Mrs',\n",
       " '.',\n",
       " 'Thwings',\n",
       " 'who',\n",
       " 'mourned',\n",
       " '.',\n",
       " 'Had',\n",
       " 'not',\n",
       " 'the',\n",
       " 'exquisite',\n",
       " 'Hermia',\n",
       " 'Croft',\n",
       " ',',\n",
       " 'at',\n",
       " 'the',\n",
       " 'last',\n",
       " 'Grafton',\n",
       " 'Gallery',\n",
       " 'show',\n",
       " ',',\n",
       " 'stopped',\n",
       " 'me',\n",
       " 'before',\n",
       " 'Gisburn',\n",
       " \"'\",\n",
       " 's',\n",
       " '\"',\n",
       " 'Moon-dancers',\n",
       " '\"',\n",
       " 'to',\n",
       " 'say',\n",
       " ',',\n",
       " 'with',\n",
       " 'tears',\n",
       " 'in',\n",
       " 'her',\n",
       " 'eyes',\n",
       " ':',\n",
       " '\"',\n",
       " 'We',\n",
       " 'shall',\n",
       " 'not',\n",
       " 'look',\n",
       " 'upon',\n",
       " 'its',\n",
       " 'like',\n",
       " 'again',\n",
       " '\"',\n",
       " '?',\n",
       " 'Well',\n",
       " '!',\n",
       " '--',\n",
       " 'even',\n",
       " 'through',\n",
       " 'the',\n",
       " 'prism',\n",
       " 'of',\n",
       " 'Hermia',\n",
       " \"'\",\n",
       " 's',\n",
       " 'tears',\n",
       " 'I',\n",
       " 'felt',\n",
       " 'able',\n",
       " 'to',\n",
       " 'face',\n",
       " 'the',\n",
       " 'fact',\n",
       " 'with',\n",
       " 'equanimity',\n",
       " '.',\n",
       " 'Poor',\n",
       " 'Jack',\n",
       " 'Gisburn',\n",
       " '!',\n",
       " 'The',\n",
       " 'women',\n",
       " 'had',\n",
       " 'made',\n",
       " 'him',\n",
       " '--',\n",
       " 'it',\n",
       " 'was',\n",
       " 'fitting',\n",
       " 'that',\n",
       " 'they',\n",
       " 'should',\n",
       " 'mourn',\n",
       " 'him',\n",
       " '.',\n",
       " 'Among',\n",
       " 'his',\n",
       " 'own',\n",
       " 'sex',\n",
       " 'fewer',\n",
       " 'regrets',\n",
       " 'were',\n",
       " 'heard',\n",
       " ',',\n",
       " 'and',\n",
       " 'in',\n",
       " 'his',\n",
       " 'own',\n",
       " 'trade',\n",
       " 'hardly',\n",
       " 'a',\n",
       " 'murmur',\n",
       " '.',\n",
       " 'Professional',\n",
       " 'jealousy',\n",
       " '?',\n",
       " 'Perhaps',\n",
       " '.',\n",
       " 'If',\n",
       " 'it',\n",
       " 'were',\n",
       " ',',\n",
       " 'the',\n",
       " 'honour',\n",
       " 'of',\n",
       " 'the',\n",
       " 'craft',\n",
       " 'was',\n",
       " 'vindicated',\n",
       " 'by',\n",
       " 'little',\n",
       " 'Claude',\n",
       " 'Nutley',\n",
       " ',',\n",
       " 'who',\n",
       " ',',\n",
       " 'in',\n",
       " 'all',\n",
       " 'good',\n",
       " 'faith',\n",
       " ',',\n",
       " 'brought',\n",
       " 'out',\n",
       " 'in',\n",
       " 'the',\n",
       " 'Burlington',\n",
       " 'a',\n",
       " 'very',\n",
       " 'handsome',\n",
       " '\"',\n",
       " 'obituary',\n",
       " '\"',\n",
       " 'on',\n",
       " 'Jack',\n",
       " '--',\n",
       " 'one',\n",
       " '2',\n",
       " 'of',\n",
       " 'those',\n",
       " 'showy',\n",
       " 'articles',\n",
       " 'stocked',\n",
       " 'with',\n",
       " 'random',\n",
       " 'technicalities',\n",
       " 'that',\n",
       " 'I',\n",
       " 'have',\n",
       " 'heard',\n",
       " '(',\n",
       " 'I',\n",
       " 'won',\n",
       " \"'\",\n",
       " 't',\n",
       " 'say',\n",
       " 'by',\n",
       " 'whom',\n",
       " ')',\n",
       " 'compared',\n",
       " 'to',\n",
       " 'Gisburn',\n",
       " \"'\",\n",
       " 's',\n",
       " 'painting',\n",
       " '.',\n",
       " 'And',\n",
       " 'so',\n",
       " '--',\n",
       " 'his',\n",
       " 'resolve',\n",
       " 'being',\n",
       " 'apparently',\n",
       " 'irrevocable',\n",
       " '--',\n",
       " 'the',\n",
       " 'discussion',\n",
       " 'gradually',\n",
       " 'died',\n",
       " 'out',\n",
       " ',',\n",
       " 'and',\n",
       " ',',\n",
       " 'as',\n",
       " 'Mrs',\n",
       " '.',\n",
       " 'Thwing',\n",
       " 'had',\n",
       " 'predicted',\n",
       " ',',\n",
       " 'the',\n",
       " 'price',\n",
       " 'of',\n",
       " '\"',\n",
       " 'Gisburns',\n",
       " '\"',\n",
       " 'went',\n",
       " 'up',\n",
       " '.',\n",
       " 'It',\n",
       " 'was',\n",
       " 'not',\n",
       " 'till',\n",
       " 'three',\n",
       " 'years',\n",
       " 'later',\n",
       " 'that',\n",
       " ',',\n",
       " 'in',\n",
       " 'the',\n",
       " 'course',\n",
       " 'of',\n",
       " 'a',\n",
       " 'few',\n",
       " 'weeks',\n",
       " \"'\",\n",
       " 'idling',\n",
       " 'on',\n",
       " 'the',\n",
       " 'Riviera',\n",
       " ',',\n",
       " 'it',\n",
       " 'suddenly',\n",
       " 'occurred',\n",
       " 'to',\n",
       " 'me',\n",
       " 'to',\n",
       " 'wonder',\n",
       " 'why',\n",
       " 'Gisburn',\n",
       " 'had',\n",
       " 'given',\n",
       " 'up',\n",
       " 'his',\n",
       " 'painting',\n",
       " '.',\n",
       " 'On',\n",
       " 'reflection',\n",
       " ',',\n",
       " 'it',\n",
       " 'really',\n",
       " 'was',\n",
       " 'a',\n",
       " 'tempting',\n",
       " 'problem',\n",
       " '.',\n",
       " 'To',\n",
       " 'accuse',\n",
       " 'his',\n",
       " 'wife',\n",
       " 'would',\n",
       " 'have',\n",
       " 'been',\n",
       " 'too',\n",
       " 'easy',\n",
       " '--',\n",
       " 'his',\n",
       " 'fair',\n",
       " 'sitters',\n",
       " 'had',\n",
       " 'been',\n",
       " 'denied',\n",
       " 'the',\n",
       " 'solace',\n",
       " 'of',\n",
       " 'saying',\n",
       " 'that',\n",
       " 'Mrs',\n",
       " '.',\n",
       " 'Gisburn',\n",
       " 'had',\n",
       " '\"',\n",
       " 'dragged',\n",
       " 'him',\n",
       " 'down',\n",
       " '.',\n",
       " '\"',\n",
       " 'For',\n",
       " 'Mrs',\n",
       " '.',\n",
       " 'Gisburn',\n",
       " '--',\n",
       " 'as',\n",
       " 'such',\n",
       " '--',\n",
       " 'had',\n",
       " 'not',\n",
       " 'existed',\n",
       " 'till',\n",
       " 'nearly',\n",
       " 'a',\n",
       " 'year',\n",
       " 'after',\n",
       " 'Jack',\n",
       " \"'\",\n",
       " 's',\n",
       " 'resolve',\n",
       " 'had',\n",
       " 'been',\n",
       " 'taken',\n",
       " '.',\n",
       " 'It',\n",
       " 'might',\n",
       " 'be',\n",
       " 'that',\n",
       " 'he',\n",
       " 'had',\n",
       " 'married',\n",
       " 'her',\n",
       " '--',\n",
       " 'since',\n",
       " 'he',\n",
       " 'liked',\n",
       " 'his',\n",
       " 'ease',\n",
       " '--',\n",
       " 'because',\n",
       " 'he',\n",
       " 'didn',\n",
       " \"'\",\n",
       " 't',\n",
       " 'want',\n",
       " 'to',\n",
       " 'go',\n",
       " 'on',\n",
       " 'painting',\n",
       " ';',\n",
       " 'but',\n",
       " 'it',\n",
       " 'would',\n",
       " 'have',\n",
       " 'been',\n",
       " 'hard',\n",
       " 'to',\n",
       " 'prove',\n",
       " 'that',\n",
       " 'he',\n",
       " 'had',\n",
       " 'given',\n",
       " 'up',\n",
       " 'his',\n",
       " 'painting',\n",
       " 'because',\n",
       " 'he',\n",
       " 'had',\n",
       " 'married',\n",
       " 'her',\n",
       " '.',\n",
       " 'Of',\n",
       " 'course',\n",
       " ',',\n",
       " 'if',\n",
       " 'she',\n",
       " 'had',\n",
       " 'not',\n",
       " 'dragged',\n",
       " 'him',\n",
       " 'down',\n",
       " ',',\n",
       " 'she',\n",
       " 'had',\n",
       " 'equally',\n",
       " ',',\n",
       " 'as',\n",
       " 'Miss',\n",
       " 'Croft',\n",
       " 'contended',\n",
       " ',',\n",
       " 'failed',\n",
       " 'to',\n",
       " '\"',\n",
       " 'lift',\n",
       " 'him',\n",
       " 'up',\n",
       " '\"',\n",
       " '-she',\n",
       " 'had',\n",
       " 'not',\n",
       " 'led',\n",
       " 'him',\n",
       " 'back',\n",
       " 'to',\n",
       " 'the',\n",
       " 'easel',\n",
       " '.',\n",
       " 'To',\n",
       " 'put',\n",
       " 'the',\n",
       " 'brush',\n",
       " 'into',\n",
       " 'his',\n",
       " 'hand',\n",
       " 'again',\n",
       " '--',\n",
       " 'what',\n",
       " 'a',\n",
       " 'vocation',\n",
       " 'for',\n",
       " 'a',\n",
       " 'wife',\n",
       " '!',\n",
       " 'But',\n",
       " 'Mrs',\n",
       " '.',\n",
       " 'Gisburn',\n",
       " 'appeared',\n",
       " 'to',\n",
       " 'have',\n",
       " 'disdained',\n",
       " 'it',\n",
       " '--',\n",
       " 'and',\n",
       " 'I',\n",
       " 'felt',\n",
       " 'it',\n",
       " 'might',\n",
       " 'be',\n",
       " 'interesting',\n",
       " 'to',\n",
       " 'find',\n",
       " 'out',\n",
       " 'why',\n",
       " '.',\n",
       " 'The',\n",
       " 'desultory',\n",
       " 'life',\n",
       " 'of',\n",
       " 'the',\n",
       " 'Riviera',\n",
       " 'lends',\n",
       " 'itself',\n",
       " 'to',\n",
       " 'such',\n",
       " 'purely',\n",
       " 'academic',\n",
       " 'speculations',\n",
       " ';',\n",
       " 'and',\n",
       " 'having',\n",
       " ',',\n",
       " 'on',\n",
       " 'my',\n",
       " 'way',\n",
       " 'to',\n",
       " 'Monte',\n",
       " '3',\n",
       " 'Carlo',\n",
       " ',',\n",
       " 'caught',\n",
       " 'a',\n",
       " 'glimpse',\n",
       " 'of',\n",
       " 'Jack',\n",
       " \"'\",\n",
       " 's',\n",
       " 'balustraded',\n",
       " 'terraces',\n",
       " 'between',\n",
       " 'the',\n",
       " 'pines',\n",
       " ',',\n",
       " 'I',\n",
       " 'had',\n",
       " 'myself',\n",
       " 'borne',\n",
       " 'thither',\n",
       " 'the',\n",
       " 'next',\n",
       " 'day',\n",
       " '.',\n",
       " 'I',\n",
       " 'found',\n",
       " 'the',\n",
       " 'couple',\n",
       " 'at',\n",
       " 'tea',\n",
       " 'beneath',\n",
       " 'their',\n",
       " 'palm-trees',\n",
       " ';',\n",
       " 'and',\n",
       " 'Mrs',\n",
       " '.',\n",
       " 'Gisburn',\n",
       " \"'\",\n",
       " 's',\n",
       " 'welcome',\n",
       " 'was',\n",
       " 'so',\n",
       " 'genial',\n",
       " 'that',\n",
       " ',',\n",
       " 'in',\n",
       " 'the',\n",
       " 'ensuing',\n",
       " 'weeks',\n",
       " ',',\n",
       " 'I',\n",
       " 'claimed',\n",
       " 'it',\n",
       " 'frequently',\n",
       " '.',\n",
       " 'It',\n",
       " 'was',\n",
       " 'not',\n",
       " 'that',\n",
       " 'my',\n",
       " 'hostess',\n",
       " 'was',\n",
       " '\"',\n",
       " 'interesting',\n",
       " '\"',\n",
       " ':',\n",
       " 'on',\n",
       " 'that',\n",
       " 'point',\n",
       " 'I',\n",
       " 'could',\n",
       " 'have',\n",
       " 'given',\n",
       " 'Miss',\n",
       " 'Croft',\n",
       " 'the',\n",
       " 'fullest',\n",
       " 'reassurance',\n",
       " '.',\n",
       " 'It',\n",
       " 'was',\n",
       " 'just',\n",
       " 'because',\n",
       " 'she',\n",
       " 'was',\n",
       " '_',\n",
       " 'not',\n",
       " '_',\n",
       " 'interesting',\n",
       " '--',\n",
       " 'if',\n",
       " 'I',\n",
       " 'may',\n",
       " 'be',\n",
       " 'pardoned',\n",
       " 'the',\n",
       " 'bull',\n",
       " '--',\n",
       " 'that',\n",
       " 'I',\n",
       " 'found',\n",
       " 'her',\n",
       " 'so',\n",
       " '.',\n",
       " 'For',\n",
       " 'Jack',\n",
       " ',',\n",
       " 'all',\n",
       " 'his',\n",
       " 'life',\n",
       " ',',\n",
       " 'had',\n",
       " 'been',\n",
       " 'surrounded',\n",
       " 'by',\n",
       " 'interesting',\n",
       " 'women',\n",
       " ':',\n",
       " 'they',\n",
       " 'had',\n",
       " 'fostered',\n",
       " 'his',\n",
       " 'art',\n",
       " ',',\n",
       " 'it',\n",
       " 'had',\n",
       " 'been',\n",
       " 'reared',\n",
       " 'in',\n",
       " 'the',\n",
       " 'hot-house',\n",
       " 'of',\n",
       " 'their',\n",
       " 'adulation',\n",
       " '.',\n",
       " 'And',\n",
       " 'it',\n",
       " 'was',\n",
       " 'therefore',\n",
       " 'instructive',\n",
       " 'to',\n",
       " 'note',\n",
       " 'what',\n",
       " 'effect',\n",
       " 'the',\n",
       " '\"',\n",
       " 'deadening',\n",
       " 'atmosphere',\n",
       " 'of',\n",
       " 'mediocrity',\n",
       " '\"',\n",
       " '(',\n",
       " 'I',\n",
       " 'quote',\n",
       " 'Miss',\n",
       " 'Croft',\n",
       " ')',\n",
       " 'was',\n",
       " 'having',\n",
       " 'on',\n",
       " 'him',\n",
       " '.',\n",
       " 'I',\n",
       " 'have',\n",
       " 'mentioned',\n",
       " 'that',\n",
       " 'Mrs',\n",
       " '.',\n",
       " 'Gisburn',\n",
       " 'was',\n",
       " 'rich',\n",
       " ';',\n",
       " 'and',\n",
       " 'it',\n",
       " 'was',\n",
       " 'immediately',\n",
       " 'perceptible',\n",
       " 'that',\n",
       " 'her',\n",
       " 'husband',\n",
       " 'was',\n",
       " 'extracting',\n",
       " 'from',\n",
       " 'this',\n",
       " 'circumstance',\n",
       " 'a',\n",
       " 'delicate',\n",
       " 'but',\n",
       " 'substantial',\n",
       " 'satisfaction',\n",
       " '.',\n",
       " 'It',\n",
       " 'is',\n",
       " ',',\n",
       " 'as',\n",
       " 'a',\n",
       " 'rule',\n",
       " ',',\n",
       " 'the',\n",
       " 'people',\n",
       " 'who',\n",
       " 'scorn',\n",
       " 'money',\n",
       " 'who',\n",
       " 'get',\n",
       " 'most',\n",
       " 'out',\n",
       " 'of',\n",
       " 'it',\n",
       " ';',\n",
       " 'and',\n",
       " 'Jack',\n",
       " \"'\",\n",
       " 's',\n",
       " 'elegant',\n",
       " 'disdain',\n",
       " 'of',\n",
       " 'his',\n",
       " 'wife',\n",
       " \"'\",\n",
       " 's',\n",
       " 'big',\n",
       " 'balance',\n",
       " 'enabled',\n",
       " 'him',\n",
       " ',',\n",
       " 'with',\n",
       " 'an',\n",
       " 'appearance',\n",
       " 'of',\n",
       " 'perfect',\n",
       " 'good-breeding',\n",
       " ',',\n",
       " 'to',\n",
       " 'transmute',\n",
       " 'it',\n",
       " 'into',\n",
       " 'objects',\n",
       " 'of',\n",
       " 'art',\n",
       " 'and',\n",
       " 'luxury',\n",
       " '.',\n",
       " 'To',\n",
       " 'the',\n",
       " 'latter',\n",
       " ',',\n",
       " 'I',\n",
       " 'must',\n",
       " 'add',\n",
       " ',',\n",
       " 'he',\n",
       " 'remained',\n",
       " 'relatively',\n",
       " 'indifferent',\n",
       " ';',\n",
       " 'but',\n",
       " 'he',\n",
       " 'was',\n",
       " 'buying',\n",
       " 'Renaissance',\n",
       " 'bronzes',\n",
       " 'and',\n",
       " 'eighteenth-century',\n",
       " 'pictures',\n",
       " 'with',\n",
       " 'a',\n",
       " 'discrimination',\n",
       " 'that',\n",
       " 'bespoke',\n",
       " 'the',\n",
       " 'amplest',\n",
       " 'resources',\n",
       " '.',\n",
       " '4',\n",
       " '\"',\n",
       " 'Money',\n",
       " \"'\",\n",
       " 's',\n",
       " 'only',\n",
       " 'excuse',\n",
       " 'is',\n",
       " 'to',\n",
       " 'put',\n",
       " 'beauty',\n",
       " 'into',\n",
       " 'circulation',\n",
       " ',',\n",
       " '\"',\n",
       " 'was',\n",
       " 'one',\n",
       " 'of',\n",
       " 'the',\n",
       " 'axioms',\n",
       " 'he',\n",
       " 'laid',\n",
       " 'down',\n",
       " 'across',\n",
       " 'the',\n",
       " 'Sevres',\n",
       " 'and',\n",
       " 'silver',\n",
       " 'of',\n",
       " 'an',\n",
       " 'exquisitely',\n",
       " 'appointed',\n",
       " 'luncheon-table',\n",
       " ',',\n",
       " 'when',\n",
       " ',',\n",
       " 'on',\n",
       " 'a',\n",
       " 'later',\n",
       " 'day',\n",
       " ',',\n",
       " 'I',\n",
       " 'had',\n",
       " 'again',\n",
       " 'run',\n",
       " 'over',\n",
       " 'from',\n",
       " 'Monte',\n",
       " 'Carlo',\n",
       " ';',\n",
       " 'and',\n",
       " 'Mrs',\n",
       " '.',\n",
       " 'Gisburn',\n",
       " ',',\n",
       " 'beaming',\n",
       " 'on',\n",
       " 'him',\n",
       " ',',\n",
       " 'added',\n",
       " 'for',\n",
       " 'my',\n",
       " 'enlightenment',\n",
       " ':',\n",
       " '\"',\n",
       " 'Jack',\n",
       " 'is',\n",
       " 'so',\n",
       " 'morbidly',\n",
       " 'sensitive',\n",
       " 'to',\n",
       " 'every',\n",
       " 'form',\n",
       " 'of',\n",
       " ...]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[item.strip() for item in preprocessed_text if item.strip()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting tokens into token ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1259"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_words = sorted(set(preprocessed_text))\n",
    "vocab_size = len(all_words)\n",
    "\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {token: integer for integer, token in enumerate(all_words)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('', 0)\n",
      "('\\n', 1)\n",
      "('\\x0c', 2)\n",
      "(' ', 3)\n",
      "('!', 4)\n",
      "('\"', 5)\n",
      "(\"'\", 6)\n",
      "('(', 7)\n",
      "(')', 8)\n",
      "(',', 9)\n",
      "('--', 10)\n",
      "('-she', 11)\n",
      "('.', 12)\n",
      "('0', 13)\n",
      "('1', 14)\n",
      "('10', 15)\n",
      "('11', 16)\n",
      "('12', 17)\n",
      "('13', 18)\n",
      "('14', 19)\n",
      "('15', 20)\n",
      "('16', 21)\n",
      "('17', 22)\n",
      "('18', 23)\n",
      "('19', 24)\n",
      "('1908', 25)\n",
      "('1929', 26)\n",
      "('2', 27)\n",
      "('20', 28)\n",
      "('2024', 29)\n",
      "('21', 30)\n",
      "('22', 31)\n",
      "('3', 32)\n",
      "('4', 33)\n",
      "('5', 34)\n",
      "('6', 35)\n",
      "('7', 36)\n",
      "('8', 37)\n",
      "('9', 38)\n",
      "(':', 39)\n",
      "(';', 40)\n",
      "('?', 41)\n",
      "('A', 42)\n",
      "('Abigor', 43)\n",
      "('About', 44)\n",
      "('AdamBMorgan', 45)\n",
      "('Ah', 46)\n",
      "('Among', 47)\n",
      "('And', 48)\n",
      "('Are', 49)\n",
      "('Arrt', 50)\n"
     ]
    }
   ],
   "source": [
    "for i, item in enumerate(vocab.items()):\n",
    "    print(item)\n",
    "    if i >= 50:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleTokenizer:\n",
    "    def __init__(self, vocab):\n",
    "        self.str_to_int = vocab\n",
    "        self.int_to_str = {i:s for s,i in vocab.items()}\n",
    "    \n",
    "    # convert the str to int\n",
    "    def encode(self, text):\n",
    "        preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s)', text)\n",
    "        preprocessed = [\n",
    "            item.strip() for item in preprocessed if item.strip()\n",
    "        ]\n",
    "        ids = [self.str_to_int[word] for word in preprocessed]\n",
    "        return ids\n",
    "    \n",
    "    # convert the int to str\n",
    "    def decode(self, ids):\n",
    "        text = \" \".join(self.int_to_str[number] for number in ids)\n",
    "        text = re.sub(r'([,.:;?_!\"()\\']|--|\\s)', r'\\1', text)\n",
    "        return text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = SimpleTokenizer(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded = tokenizer.encode(\"in a villa on the Riviera. (Though I rather thought it would\")\n",
    "decoded = tokenizer.decode(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoded:  [667, 187, 1192, 836, 1111, 143, 12, 7, 163, 104, 936, 1126, 685, 1249]\n",
      "decoded:  in a villa on the Riviera . ( Though I rather thought it would\n"
     ]
    }
   ],
   "source": [
    "print(\"encoded: \", encoded)\n",
    "print(\"decoded: \", decoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BytePair Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tiktoken\n",
      "  Downloading tiktoken-0.8.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting regex>=2022.1.18 (from tiktoken)\n",
      "  Using cached regex-2024.11.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Collecting requests>=2.26.0 (from tiktoken)\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests>=2.26.0->tiktoken)\n",
      "  Using cached charset_normalizer-3.4.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (34 kB)\n",
      "Collecting idna<4,>=2.5 (from requests>=2.26.0->tiktoken)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests>=2.26.0->tiktoken)\n",
      "  Downloading urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests>=2.26.0->tiktoken)\n",
      "  Using cached certifi-2024.12.14-py3-none-any.whl.metadata (2.3 kB)\n",
      "Downloading tiktoken-0.8.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached regex-2024.11.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (796 kB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Using cached certifi-2024.12.14-py3-none-any.whl (164 kB)\n",
      "Using cached charset_normalizer-3.4.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (143 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Downloading urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
      "Installing collected packages: urllib3, regex, idna, charset-normalizer, certifi, requests, tiktoken\n",
      "Successfully installed certifi-2024.12.14 charset-normalizer-3.4.0 idna-3.10 regex-2024.11.6 requests-2.32.3 tiktoken-0.8.0 urllib3-2.3.0\n"
     ]
    }
   ],
   "source": [
    "! pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tiktoken version:  0.8.0\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import importlib.metadata\n",
    "import tiktoken\n",
    "\n",
    "print(\"tiktoken version: \", importlib.metadata.version(\"tiktoken\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[15496,\n",
       " 11,\n",
       " 466,\n",
       " 345,\n",
       " 588,\n",
       " 262,\n",
       " 6891,\n",
       " 30,\n",
       " 703,\n",
       " 389,\n",
       " 345,\n",
       " 220,\n",
       " 50256,\n",
       " 314,\n",
       " 716,\n",
       " 922,\n",
       " 290,\n",
       " 345]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's use the gpts tokenizer using tiktoken\n",
    "text = (\n",
    "    \"Hello, do you like the coffee? how are you <|endoftext|> \" \n",
    "    \"I am good and you\"\n",
    "\n",
    ")\n",
    "\n",
    "encoded = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
    "encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello, do you like the coffee? how are you <|endoftext|> I am good and you'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded = tokenizer.decode(encoded)\n",
    "decoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data sampling with a sliding window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Using cached torch-2.5.1-cp312-cp312-manylinux1_x86_64.whl.metadata (28 kB)\n",
      "Collecting filelock (from torch)\n",
      "  Using cached filelock-3.16.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting typing-extensions>=4.8.0 (from torch)\n",
      "  Using cached typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting networkx (from torch)\n",
      "  Using cached networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting jinja2 (from torch)\n",
      "  Downloading jinja2-3.1.5-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting fsspec (from torch)\n",
      "  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
      "  Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
      "  Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
      "  Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
      "  Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
      "  Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
      "  Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nccl-cu12==2.21.5 (from torch)\n",
      "  Using cached nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.4.127 (from torch)\n",
      "  Using cached nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
      "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting triton==3.1.0 (from torch)\n",
      "  Using cached triton-3.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
      "Collecting setuptools (from torch)\n",
      "  Using cached setuptools-75.6.0-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting sympy==1.13.1 (from torch)\n",
      "  Using cached sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch)\n",
      "  Using cached MarkupSafe-3.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
      "Using cached torch-2.5.1-cp312-cp312-manylinux1_x86_64.whl (906.4 MB)\n",
      "Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "Using cached nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
      "Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "Using cached nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
      "Using cached sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "Using cached triton-3.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.6 MB)\n",
      "Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Using cached filelock-3.16.1-py3-none-any.whl (16 kB)\n",
      "Downloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
      "Downloading jinja2-3.1.5-py3-none-any.whl (134 kB)\n",
      "Using cached networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "Using cached setuptools-75.6.0-py3-none-any.whl (1.2 MB)\n",
      "Using cached MarkupSafe-3.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23 kB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Installing collected packages: mpmath, typing-extensions, sympy, setuptools, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, networkx, MarkupSafe, fsspec, filelock, triton, nvidia-cusparse-cu12, nvidia-cudnn-cu12, jinja2, nvidia-cusolver-cu12, torch\n",
      "Successfully installed MarkupSafe-3.0.2 filelock-3.16.1 fsspec-2024.12.0 jinja2-3.1.5 mpmath-1.3.0 networkx-3.4.2 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 setuptools-75.6.0 sympy-1.13.1 torch-2.5.1 triton-3.1.0 typing-extensions-4.12.2\n",
      "Requirement already satisfied: torch>=2.0.1 in /home/farzin/AI/Sebastian Raschka/.venv/lib/python3.12/site-packages (from -r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 1)) (2.5.1)\n",
      "Collecting jupyterlab>=4.0 (from -r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 2))\n",
      "  Downloading jupyterlab-4.3.4-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: tiktoken>=0.5.1 in /home/farzin/AI/Sebastian Raschka/.venv/lib/python3.12/site-packages (from -r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 3)) (0.8.0)\n",
      "Collecting matplotlib>=3.7.1 (from -r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 4))\n",
      "  Downloading matplotlib-3.10.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting tensorflow>=2.15.0 (from -r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 5))\n",
      "  Downloading tensorflow-2.18.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "Collecting tqdm>=4.66.1 (from -r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 6))\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting numpy<2.0,>=1.25 (from -r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 7))\n",
      "  Using cached numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Collecting pandas>=2.2.1 (from -r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 8))\n",
      "  Using cached pandas-2.2.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
      "Requirement already satisfied: psutil>=5.9.5 in /home/farzin/AI/Sebastian Raschka/.venv/lib/python3.12/site-packages (from -r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 9)) (6.1.1)\n",
      "Requirement already satisfied: filelock in /home/farzin/AI/Sebastian Raschka/.venv/lib/python3.12/site-packages (from torch>=2.0.1->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 1)) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/farzin/AI/Sebastian Raschka/.venv/lib/python3.12/site-packages (from torch>=2.0.1->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 1)) (4.12.2)\n",
      "Requirement already satisfied: networkx in /home/farzin/AI/Sebastian Raschka/.venv/lib/python3.12/site-packages (from torch>=2.0.1->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 1)) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/farzin/AI/Sebastian Raschka/.venv/lib/python3.12/site-packages (from torch>=2.0.1->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 1)) (3.1.5)\n",
      "Requirement already satisfied: fsspec in /home/farzin/AI/Sebastian Raschka/.venv/lib/python3.12/site-packages (from torch>=2.0.1->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 1)) (2024.12.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /home/farzin/AI/Sebastian Raschka/.venv/lib/python3.12/site-packages (from torch>=2.0.1->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 1)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /home/farzin/AI/Sebastian Raschka/.venv/lib/python3.12/site-packages (from torch>=2.0.1->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 1)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /home/farzin/AI/Sebastian Raschka/.venv/lib/python3.12/site-packages (from torch>=2.0.1->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 1)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/farzin/AI/Sebastian Raschka/.venv/lib/python3.12/site-packages (from torch>=2.0.1->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 1)) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /home/farzin/AI/Sebastian Raschka/.venv/lib/python3.12/site-packages (from torch>=2.0.1->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 1)) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /home/farzin/AI/Sebastian Raschka/.venv/lib/python3.12/site-packages (from torch>=2.0.1->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 1)) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /home/farzin/AI/Sebastian Raschka/.venv/lib/python3.12/site-packages (from torch>=2.0.1->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 1)) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /home/farzin/AI/Sebastian Raschka/.venv/lib/python3.12/site-packages (from torch>=2.0.1->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 1)) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /home/farzin/AI/Sebastian Raschka/.venv/lib/python3.12/site-packages (from torch>=2.0.1->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 1)) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/farzin/AI/Sebastian Raschka/.venv/lib/python3.12/site-packages (from torch>=2.0.1->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 1)) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /home/farzin/AI/Sebastian Raschka/.venv/lib/python3.12/site-packages (from torch>=2.0.1->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 1)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /home/farzin/AI/Sebastian Raschka/.venv/lib/python3.12/site-packages (from torch>=2.0.1->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 1)) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /home/farzin/AI/Sebastian Raschka/.venv/lib/python3.12/site-packages (from torch>=2.0.1->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 1)) (3.1.0)\n",
      "Requirement already satisfied: setuptools in /home/farzin/AI/Sebastian Raschka/.venv/lib/python3.12/site-packages (from torch>=2.0.1->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 1)) (75.6.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/farzin/AI/Sebastian Raschka/.venv/lib/python3.12/site-packages (from torch>=2.0.1->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 1)) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/farzin/AI/Sebastian Raschka/.venv/lib/python3.12/site-packages (from sympy==1.13.1->torch>=2.0.1->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 1)) (1.3.0)\n",
      "Collecting async-lru>=1.0.0 (from jupyterlab>=4.0->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 2))\n",
      "  Downloading async_lru-2.0.4-py3-none-any.whl.metadata (4.5 kB)\n",
      "Collecting httpx>=0.25.0 (from jupyterlab>=4.0->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 2))\n",
      "  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: ipykernel>=6.5.0 in /home/farzin/AI/Sebastian Raschka/.venv/lib/python3.12/site-packages (from jupyterlab>=4.0->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 2)) (6.29.5)\n",
      "Requirement already satisfied: jupyter-core in /home/farzin/AI/Sebastian Raschka/.venv/lib/python3.12/site-packages (from jupyterlab>=4.0->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 2)) (5.7.2)\n",
      "Collecting jupyter-lsp>=2.0.0 (from jupyterlab>=4.0->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 2))\n",
      "  Downloading jupyter_lsp-2.2.5-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting jupyter-server<3,>=2.4.0 (from jupyterlab>=4.0->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 2))\n",
      "  Downloading jupyter_server-2.15.0-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting jupyterlab-server<3,>=2.27.1 (from jupyterlab>=4.0->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 2))\n",
      "  Downloading jupyterlab_server-2.27.3-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting notebook-shim>=0.2 (from jupyterlab>=4.0->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 2))\n",
      "  Downloading notebook_shim-0.2.4-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: packaging in /home/farzin/AI/Sebastian Raschka/.venv/lib/python3.12/site-packages (from jupyterlab>=4.0->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 2)) (24.2)\n",
      "Requirement already satisfied: tornado>=6.2.0 in /home/farzin/AI/Sebastian Raschka/.venv/lib/python3.12/site-packages (from jupyterlab>=4.0->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 2)) (6.4.2)\n",
      "Requirement already satisfied: traitlets in /home/farzin/AI/Sebastian Raschka/.venv/lib/python3.12/site-packages (from jupyterlab>=4.0->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 2)) (5.14.3)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /home/farzin/AI/Sebastian Raschka/.venv/lib/python3.12/site-packages (from tiktoken>=0.5.1->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 3)) (2024.11.6)\n",
      "Requirement already satisfied: requests>=2.26.0 in /home/farzin/AI/Sebastian Raschka/.venv/lib/python3.12/site-packages (from tiktoken>=0.5.1->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 3)) (2.32.3)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib>=3.7.1->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 4))\n",
      "  Downloading contourpy-1.3.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.4 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib>=3.7.1->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 4))\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib>=3.7.1->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 4))\n",
      "  Downloading fonttools-4.55.3-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (165 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib>=3.7.1->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 4))\n",
      "  Downloading kiwisolver-1.4.7-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.3 kB)\n",
      "Collecting pillow>=8 (from matplotlib>=3.7.1->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 4))\n",
      "  Using cached pillow-11.0.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (9.1 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib>=3.7.1->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 4))\n",
      "  Using cached pyparsing-3.2.0-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/farzin/AI/Sebastian Raschka/.venv/lib/python3.12/site-packages (from matplotlib>=3.7.1->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 4)) (2.9.0.post0)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow>=2.15.0->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 5))\n",
      "  Using cached absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow>=2.15.0->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 5))\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow>=2.15.0->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 5))\n",
      "  Using cached flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow>=2.15.0->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 5))\n",
      "  Using cached gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow>=2.15.0->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 5))\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow>=2.15.0->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 5))\n",
      "  Using cached libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow>=2.15.0->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 5))\n",
      "  Using cached opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 (from tensorflow>=2.15.0->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 5))\n",
      "  Downloading protobuf-5.29.2-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/farzin/AI/Sebastian Raschka/.venv/lib/python3.12/site-packages (from tensorflow>=2.15.0->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 5)) (1.17.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow>=2.15.0->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 5))\n",
      "  Using cached termcolor-2.5.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow>=2.15.0->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 5))\n",
      "  Downloading wrapt-1.17.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow>=2.15.0->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 5))\n",
      "  Downloading grpcio-1.68.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\n",
      "Collecting tensorboard<2.19,>=2.18 (from tensorflow>=2.15.0->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 5))\n",
      "  Downloading tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting keras>=3.5.0 (from tensorflow>=2.15.0->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 5))\n",
      "  Downloading keras-3.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting h5py>=3.11.0 (from tensorflow>=2.15.0->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 5))\n",
      "  Using cached h5py-3.12.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
      "Collecting ml-dtypes<0.5.0,>=0.4.0 (from tensorflow>=2.15.0->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 5))\n",
      "  Using cached ml_dtypes-0.4.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Collecting pytz>=2020.1 (from pandas>=2.2.1->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 8))\n",
      "  Using cached pytz-2024.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas>=2.2.1->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 8))\n",
      "  Using cached tzdata-2024.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting wheel<1.0,>=0.23.0 (from astunparse>=1.6.0->tensorflow>=2.15.0->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 5))\n",
      "  Downloading wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting anyio (from httpx>=0.25.0->jupyterlab>=4.0->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 2))\n",
      "  Downloading anyio-4.7.0-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: certifi in /home/farzin/AI/Sebastian Raschka/.venv/lib/python3.12/site-packages (from httpx>=0.25.0->jupyterlab>=4.0->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 2)) (2024.12.14)\n",
      "Collecting httpcore==1.* (from httpx>=0.25.0->jupyterlab>=4.0->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 2))\n",
      "  Downloading httpcore-1.0.7-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: idna in /home/farzin/AI/Sebastian Raschka/.venv/lib/python3.12/site-packages (from httpx>=0.25.0->jupyterlab>=4.0->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 2)) (3.10)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.25.0->jupyterlab>=4.0->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 2))\n",
      "  Using cached h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Requirement already satisfied: comm>=0.1.1 in /home/farzin/AI/Sebastian Raschka/.venv/lib/python3.12/site-packages (from ipykernel>=6.5.0->jupyterlab>=4.0->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 2)) (0.2.2)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /home/farzin/AI/Sebastian Raschka/.venv/lib/python3.12/site-packages (from ipykernel>=6.5.0->jupyterlab>=4.0->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 2)) (1.8.11)\n",
      "Requirement already satisfied: ipython>=7.23.1 in /home/farzin/AI/Sebastian Raschka/.venv/lib/python3.12/site-packages (from ipykernel>=6.5.0->jupyterlab>=4.0->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 2)) (8.31.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /home/farzin/AI/Sebastian Raschka/.venv/lib/python3.12/site-packages (from ipykernel>=6.5.0->jupyterlab>=4.0->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 2)) (8.6.3)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /home/farzin/AI/Sebastian Raschka/.venv/lib/python3.12/site-packages (from ipykernel>=6.5.0->jupyterlab>=4.0->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 2)) (0.1.7)\n",
      "Requirement already satisfied: nest-asyncio in /home/farzin/AI/Sebastian Raschka/.venv/lib/python3.12/site-packages (from ipykernel>=6.5.0->jupyterlab>=4.0->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 2)) (1.6.0)\n",
      "Requirement already satisfied: pyzmq>=24 in /home/farzin/AI/Sebastian Raschka/.venv/lib/python3.12/site-packages (from ipykernel>=6.5.0->jupyterlab>=4.0->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 2)) (26.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/farzin/AI/Sebastian Raschka/.venv/lib/python3.12/site-packages (from jinja2->torch>=2.0.1->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 1)) (3.0.2)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /home/farzin/AI/Sebastian Raschka/.venv/lib/python3.12/site-packages (from jupyter-core->jupyterlab>=4.0->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 2)) (4.3.6)\n",
      "Collecting argon2-cffi>=21.1 (from jupyter-server<3,>=2.4.0->jupyterlab>=4.0->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 2))\n",
      "  Downloading argon2_cffi-23.1.0-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting jupyter-events>=0.11.0 (from jupyter-server<3,>=2.4.0->jupyterlab>=4.0->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 2))\n",
      "  Downloading jupyter_events-0.11.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting jupyter-server-terminals>=0.4.4 (from jupyter-server<3,>=2.4.0->jupyterlab>=4.0->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 2))\n",
      "  Downloading jupyter_server_terminals-0.5.3-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting nbconvert>=6.4.4 (from jupyter-server<3,>=2.4.0->jupyterlab>=4.0->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 2))\n",
      "  Using cached nbconvert-7.16.4-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting nbformat>=5.3.0 (from jupyter-server<3,>=2.4.0->jupyterlab>=4.0->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 2))\n",
      "  Using cached nbformat-5.10.4-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting overrides>=5.0 (from jupyter-server<3,>=2.4.0->jupyterlab>=4.0->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 2))\n",
      "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting prometheus-client>=0.9 (from jupyter-server<3,>=2.4.0->jupyterlab>=4.0->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 2))\n",
      "  Downloading prometheus_client-0.21.1-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting send2trash>=1.8.2 (from jupyter-server<3,>=2.4.0->jupyterlab>=4.0->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 2))\n",
      "  Downloading Send2Trash-1.8.3-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting terminado>=0.8.3 (from jupyter-server<3,>=2.4.0->jupyterlab>=4.0->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 2))\n",
      "  Downloading terminado-0.18.1-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting websocket-client>=1.7 (from jupyter-server<3,>=2.4.0->jupyterlab>=4.0->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 2))\n",
      "  Downloading websocket_client-1.8.0-py3-none-any.whl.metadata (8.0 kB)\n",
      "Collecting babel>=2.10 (from jupyterlab-server<3,>=2.27.1->jupyterlab>=4.0->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 2))\n",
      "  Downloading babel-2.16.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting json5>=0.9.0 (from jupyterlab-server<3,>=2.27.1->jupyterlab>=4.0->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 2))\n",
      "  Downloading json5-0.10.0-py3-none-any.whl.metadata (34 kB)\n",
      "Collecting jsonschema>=4.18.0 (from jupyterlab-server<3,>=2.27.1->jupyterlab>=4.0->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 2))\n",
      "  Using cached jsonschema-4.23.0-py3-none-any.whl.metadata (7.9 kB)\n",
      "Collecting rich (from keras>=3.5.0->tensorflow>=2.15.0->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 5))\n",
      "  Using cached rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting namex (from keras>=3.5.0->tensorflow>=2.15.0->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 5))\n",
      "  Using cached namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n",
      "Collecting optree (from keras>=3.5.0->tensorflow>=2.15.0->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 5))\n",
      "  Downloading optree-0.13.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (47 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/farzin/AI/Sebastian Raschka/.venv/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken>=0.5.1->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 3)) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/farzin/AI/Sebastian Raschka/.venv/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken>=0.5.1->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 3)) (2.3.0)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.19,>=2.18->tensorflow>=2.15.0->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 5))\n",
      "  Using cached Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.19,>=2.18->tensorflow>=2.15.0->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 5))\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard<2.19,>=2.18->tensorflow>=2.15.0->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 5))\n",
      "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting sniffio>=1.1 (from anyio->httpx>=0.25.0->jupyterlab>=4.0->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 2))\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting argon2-cffi-bindings (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 2))\n",
      "  Downloading argon2_cffi_bindings-21.2.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: decorator in /home/farzin/AI/Sebastian Raschka/.venv/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab>=4.0->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 2)) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/farzin/AI/Sebastian Raschka/.venv/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab>=4.0->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 2)) (0.19.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /home/farzin/AI/Sebastian Raschka/.venv/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab>=4.0->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 2)) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /home/farzin/AI/Sebastian Raschka/.venv/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab>=4.0->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 2)) (3.0.48)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /home/farzin/AI/Sebastian Raschka/.venv/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab>=4.0->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 2)) (2.18.0)\n",
      "Requirement already satisfied: stack_data in /home/farzin/AI/Sebastian Raschka/.venv/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab>=4.0->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 2)) (0.6.3)\n",
      "Collecting attrs>=22.2.0 (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab>=4.0->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 2))\n",
      "  Using cached attrs-24.3.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab>=4.0->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 2))\n",
      "  Using cached jsonschema_specifications-2024.10.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting referencing>=0.28.4 (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab>=4.0->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 2))\n",
      "  Using cached referencing-0.35.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting rpds-py>=0.7.1 (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab>=4.0->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 2))\n",
      "  Downloading rpds_py-0.22.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
      "Collecting python-json-logger>=2.0.4 (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 2))\n",
      "  Downloading python_json_logger-3.2.1-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting pyyaml>=5.3 (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 2))\n",
      "  Using cached PyYAML-6.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting rfc3339-validator (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 2))\n",
      "  Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting rfc3986-validator>=0.1.1 (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 2))\n",
      "  Downloading rfc3986_validator-0.1.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting beautifulsoup4 (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 2))\n",
      "  Using cached beautifulsoup4-4.12.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting bleach!=5.0.0 (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 2))\n",
      "  Downloading bleach-6.2.0-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting defusedxml (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 2))\n",
      "  Using cached defusedxml-0.7.1-py2.py3-none-any.whl.metadata (32 kB)\n",
      "Collecting jupyterlab-pygments (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 2))\n",
      "  Using cached jupyterlab_pygments-0.3.0-py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting mistune<4,>=2.0.3 (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 2))\n",
      "  Using cached mistune-3.0.2-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting nbclient>=0.5.0 (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 2))\n",
      "  Downloading nbclient-0.10.2-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting pandocfilters>=1.4.1 (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 2))\n",
      "  Using cached pandocfilters-1.5.1-py2.py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting tinycss2 (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 2))\n",
      "  Downloading tinycss2-1.4.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting fastjsonschema>=2.15 (from nbformat>=5.3.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 2))\n",
      "  Downloading fastjsonschema-2.21.1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: ptyprocess in /home/farzin/AI/Sebastian Raschka/.venv/lib/python3.12/site-packages (from terminado>=0.8.3->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 2)) (0.7.0)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->keras>=3.5.0->tensorflow>=2.15.0->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 5))\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting webencodings (from bleach!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 2))\n",
      "  Using cached webencodings-0.5.1-py2.py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /home/farzin/AI/Sebastian Raschka/.venv/lib/python3.12/site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab>=4.0->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 2)) (0.8.4)\n",
      "Collecting fqdn (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 2))\n",
      "  Downloading fqdn-1.5.1-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting isoduration (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 2))\n",
      "  Downloading isoduration-20.11.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting jsonpointer>1.13 (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 2))\n",
      "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting uri-template (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 2))\n",
      "  Downloading uri_template-1.3.0-py3-none-any.whl.metadata (8.8 kB)\n",
      "Collecting webcolors>=24.6.0 (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 2))\n",
      "  Downloading webcolors-24.11.1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow>=2.15.0->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 5))\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: wcwidth in /home/farzin/AI/Sebastian Raschka/.venv/lib/python3.12/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab>=4.0->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 2)) (0.2.13)\n",
      "Collecting cffi>=1.0.1 (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 2))\n",
      "  Downloading cffi-1.17.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 2))\n",
      "  Using cached soupsieve-2.6-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: executing>=1.2.0 in /home/farzin/AI/Sebastian Raschka/.venv/lib/python3.12/site-packages (from stack_data->ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab>=4.0->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 2)) (2.1.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /home/farzin/AI/Sebastian Raschka/.venv/lib/python3.12/site-packages (from stack_data->ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab>=4.0->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 2)) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in /home/farzin/AI/Sebastian Raschka/.venv/lib/python3.12/site-packages (from stack_data->ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab>=4.0->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 2)) (0.2.3)\n",
      "Collecting pycparser (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 2))\n",
      "  Downloading pycparser-2.22-py3-none-any.whl.metadata (943 bytes)\n",
      "Collecting arrow>=0.15.0 (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 2))\n",
      "  Downloading arrow-1.3.0-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting types-python-dateutil>=2.8.10 (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt (line 2))\n",
      "  Downloading types_python_dateutil-2.9.0.20241206-py3-none-any.whl.metadata (2.1 kB)\n",
      "Downloading jupyterlab-4.3.4-py3-none-any.whl (11.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.7/11.7 MB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading matplotlib-3.10.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow-2.18.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (615.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m615.5/615.5 MB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
      "Using cached pandas-2.2.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.7 MB)\n",
      "Using cached absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading async_lru-2.0.4-py3-none-any.whl (6.1 kB)\n",
      "Downloading contourpy-1.3.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (323 kB)\n",
      "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Using cached flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Downloading fonttools-4.55.3-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading grpcio-1.68.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached h5py-3.12.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
      "Downloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Downloading httpcore-1.0.7-py3-none-any.whl (78 kB)\n",
      "Downloading jupyter_lsp-2.2.5-py3-none-any.whl (69 kB)\n",
      "Downloading jupyter_server-2.15.0-py3-none-any.whl (385 kB)\n",
      "Downloading jupyterlab_server-2.27.3-py3-none-any.whl (59 kB)\n",
      "Downloading keras-3.7.0-py3-none-any.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading kiwisolver-1.4.7-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
      "Using cached ml_dtypes-0.4.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
      "Downloading notebook_shim-0.2.4-py3-none-any.whl (13 kB)\n",
      "Using cached opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Using cached pillow-11.0.0-cp312-cp312-manylinux_2_28_x86_64.whl (4.4 MB)\n",
      "Downloading protobuf-5.29.2-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
      "Using cached pyparsing-3.2.0-py3-none-any.whl (106 kB)\n",
      "Using cached pytz-2024.2-py2.py3-none-any.whl (508 kB)\n",
      "Downloading tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached termcolor-2.5.0-py3-none-any.whl (7.8 kB)\n",
      "Using cached tzdata-2024.2-py2.py3-none-any.whl (346 kB)\n",
      "Downloading wrapt-1.17.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (89 kB)\n",
      "Downloading anyio-4.7.0-py3-none-any.whl (93 kB)\n",
      "Downloading argon2_cffi-23.1.0-py3-none-any.whl (15 kB)\n",
      "Downloading babel-2.16.0-py3-none-any.whl (9.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading json5-0.10.0-py3-none-any.whl (34 kB)\n",
      "Using cached jsonschema-4.23.0-py3-none-any.whl (88 kB)\n",
      "Downloading jupyter_events-0.11.0-py3-none-any.whl (19 kB)\n",
      "Downloading jupyter_server_terminals-0.5.3-py3-none-any.whl (13 kB)\n",
      "Using cached Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "Using cached nbconvert-7.16.4-py3-none-any.whl (257 kB)\n",
      "Using cached nbformat-5.10.4-py3-none-any.whl (78 kB)\n",
      "Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
      "Downloading prometheus_client-0.21.1-py3-none-any.whl (54 kB)\n",
      "Downloading Send2Trash-1.8.3-py3-none-any.whl (18 kB)\n",
      "Using cached tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
      "Downloading terminado-0.18.1-py3-none-any.whl (14 kB)\n",
      "Downloading websocket_client-1.8.0-py3-none-any.whl (58 kB)\n",
      "Downloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Downloading wheel-0.45.1-py3-none-any.whl (72 kB)\n",
      "Using cached namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Downloading optree-0.13.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (385 kB)\n",
      "Using cached rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "Using cached attrs-24.3.0-py3-none-any.whl (63 kB)\n",
      "Downloading bleach-6.2.0-py3-none-any.whl (163 kB)\n",
      "Downloading fastjsonschema-2.21.1-py3-none-any.whl (23 kB)\n",
      "Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Using cached jsonschema_specifications-2024.10.1-py3-none-any.whl (18 kB)\n",
      "Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Using cached mistune-3.0.2-py3-none-any.whl (47 kB)\n",
      "Downloading nbclient-0.10.2-py3-none-any.whl (25 kB)\n",
      "Using cached pandocfilters-1.5.1-py2.py3-none-any.whl (8.7 kB)\n",
      "Downloading python_json_logger-3.2.1-py3-none-any.whl (14 kB)\n",
      "Using cached PyYAML-6.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (767 kB)\n",
      "Using cached referencing-0.35.1-py3-none-any.whl (26 kB)\n",
      "Downloading rfc3986_validator-0.1.1-py2.py3-none-any.whl (4.2 kB)\n",
      "Downloading rpds_py-0.22.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (385 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Downloading argon2_cffi_bindings-21.2.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (86 kB)\n",
      "Using cached beautifulsoup4-4.12.3-py3-none-any.whl (147 kB)\n",
      "Using cached defusedxml-0.7.1-py2.py3-none-any.whl (25 kB)\n",
      "Using cached jupyterlab_pygments-0.3.0-py3-none-any.whl (15 kB)\n",
      "Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl (3.5 kB)\n",
      "Downloading tinycss2-1.4.0-py3-none-any.whl (26 kB)\n",
      "Downloading cffi-1.17.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (479 kB)\n",
      "Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Using cached soupsieve-2.6-py3-none-any.whl (36 kB)\n",
      "Downloading webcolors-24.11.1-py3-none-any.whl (14 kB)\n",
      "Using cached webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
      "Downloading fqdn-1.5.1-py3-none-any.whl (9.1 kB)\n",
      "Downloading isoduration-20.11.0-py3-none-any.whl (11 kB)\n",
      "Downloading uri_template-1.3.0-py3-none-any.whl (11 kB)\n",
      "Downloading arrow-1.3.0-py3-none-any.whl (66 kB)\n",
      "Downloading pycparser-2.22-py3-none-any.whl (117 kB)\n",
      "Downloading types_python_dateutil-2.9.0.20241206-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: webencodings, pytz, namex, libclang, flatbuffers, fastjsonschema, wrapt, wheel, werkzeug, websocket-client, webcolors, uri-template, tzdata, types-python-dateutil, tqdm, tinycss2, terminado, termcolor, tensorboard-data-server, soupsieve, sniffio, send2trash, rpds-py, rfc3986-validator, rfc3339-validator, pyyaml, python-json-logger, pyparsing, pycparser, protobuf, prometheus-client, pillow, pandocfilters, overrides, optree, opt-einsum, numpy, mistune, mdurl, markdown, kiwisolver, jupyterlab-pygments, jsonpointer, json5, h11, grpcio, google-pasta, gast, fqdn, fonttools, defusedxml, cycler, bleach, babel, attrs, async-lru, absl-py, tensorboard, referencing, pandas, ml-dtypes, markdown-it-py, jupyter-server-terminals, httpcore, h5py, contourpy, cffi, beautifulsoup4, astunparse, arrow, anyio, rich, matplotlib, jsonschema-specifications, isoduration, httpx, argon2-cffi-bindings, keras, jsonschema, argon2-cffi, tensorflow, nbformat, nbclient, jupyter-events, nbconvert, jupyter-server, notebook-shim, jupyterlab-server, jupyter-lsp, jupyterlab\n",
      "Successfully installed absl-py-2.1.0 anyio-4.7.0 argon2-cffi-23.1.0 argon2-cffi-bindings-21.2.0 arrow-1.3.0 astunparse-1.6.3 async-lru-2.0.4 attrs-24.3.0 babel-2.16.0 beautifulsoup4-4.12.3 bleach-6.2.0 cffi-1.17.1 contourpy-1.3.1 cycler-0.12.1 defusedxml-0.7.1 fastjsonschema-2.21.1 flatbuffers-24.3.25 fonttools-4.55.3 fqdn-1.5.1 gast-0.6.0 google-pasta-0.2.0 grpcio-1.68.1 h11-0.14.0 h5py-3.12.1 httpcore-1.0.7 httpx-0.28.1 isoduration-20.11.0 json5-0.10.0 jsonpointer-3.0.0 jsonschema-4.23.0 jsonschema-specifications-2024.10.1 jupyter-events-0.11.0 jupyter-lsp-2.2.5 jupyter-server-2.15.0 jupyter-server-terminals-0.5.3 jupyterlab-4.3.4 jupyterlab-pygments-0.3.0 jupyterlab-server-2.27.3 keras-3.7.0 kiwisolver-1.4.7 libclang-18.1.1 markdown-3.7 markdown-it-py-3.0.0 matplotlib-3.10.0 mdurl-0.1.2 mistune-3.0.2 ml-dtypes-0.4.1 namex-0.0.8 nbclient-0.10.2 nbconvert-7.16.4 nbformat-5.10.4 notebook-shim-0.2.4 numpy-1.26.4 opt-einsum-3.4.0 optree-0.13.1 overrides-7.7.0 pandas-2.2.3 pandocfilters-1.5.1 pillow-11.0.0 prometheus-client-0.21.1 protobuf-5.29.2 pycparser-2.22 pyparsing-3.2.0 python-json-logger-3.2.1 pytz-2024.2 pyyaml-6.0.2 referencing-0.35.1 rfc3339-validator-0.1.4 rfc3986-validator-0.1.1 rich-13.9.4 rpds-py-0.22.3 send2trash-1.8.3 sniffio-1.3.1 soupsieve-2.6 tensorboard-2.18.0 tensorboard-data-server-0.7.2 tensorflow-2.18.0 termcolor-2.5.0 terminado-0.18.1 tinycss2-1.4.0 tqdm-4.67.1 types-python-dateutil-2.9.0.20241206 tzdata-2024.2 uri-template-1.3.0 webcolors-24.11.1 webencodings-0.5.1 websocket-client-1.8.0 werkzeug-3.1.3 wheel-0.45.1 wrapt-1.17.0\n"
     ]
    }
   ],
   "source": [
    "! pip install torch\n",
    "! pip install -r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tiktoken\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class GPTDatasetV1(Dataset):\n",
    "    def __init__(self, txt, tokenizer, max_length, stride):\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "\n",
    "        # Tokenize the entire text\n",
    "        token_ids = tokenizer.encode(txt, allowed_special={\"<|endoftext|>\"})\n",
    "\n",
    "        # Use a sliding window to chunk the book into overlapping sequences of max_length\n",
    "        for i in range(0, len(token_ids) - max_length, stride):\n",
    "            input_chunk = token_ids[i:i + max_length]\n",
    "            target_chunk = token_ids[i + 1: i + max_length + 1]\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "            self.target_ids.append(torch.tensor(target_chunk))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.target_ids[idx]\n",
    "\n",
    "\n",
    "def create_dataloader_v1(txt, batch_size=4, max_length=256, \n",
    "                         stride=128, shuffle=True, drop_last=True, num_workers=0):\n",
    "    # Initialize the tokenizer\n",
    "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "    # Create dataset\n",
    "    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
    "\n",
    "    # Create dataloader\n",
    "    dataloader = DataLoader(\n",
    "        dataset, batch_size=batch_size, shuffle=shuffle, drop_last=drop_last, num_workers=num_workers)\n",
    "\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs:\n",
      " tensor([[  464,  4643, 11600,   198],\n",
      "        [ 4643, 11600,   198,  7407],\n",
      "        [11600,   198,  7407,   342],\n",
      "        [  198,  7407,   342,   854],\n",
      "        [ 7407,   342,   854, 41328],\n",
      "        [  342,   854, 41328,   198],\n",
      "        [  854, 41328,   198,   198],\n",
      "        [41328,   198,   198,  1129]])\n",
      "\n",
      "Targets:\n",
      " tensor([[ 4643, 11600,   198,  7407],\n",
      "        [11600,   198,  7407,   342],\n",
      "        [  198,  7407,   342,   854],\n",
      "        [ 7407,   342,   854, 41328],\n",
      "        [  342,   854, 41328,   198],\n",
      "        [  854, 41328,   198,   198],\n",
      "        [41328,   198,   198,  1129],\n",
      "        [  198,   198,  1129,  2919]])\n"
     ]
    }
   ],
   "source": [
    "dataloader = create_dataloader_v1(raw_text, batch_size=8, max_length=4, stride=4, shuffle=False)\n",
    "\n",
    "data_iter = iter(dataloader)\n",
    "inputs, targets = next(data_iter)\n",
    "\n",
    "print(\"Inputs:\\n\", inputs)\n",
    "print(\"\\nTargets:\\n\", targets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
